{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fff3e8e-5d90-48b9-bf2b-41d553d96211",
   "metadata": {},
   "source": [
    "# Selección de datasets \n",
    "\n",
    "En este tonebook se analizarán datasets de datos, tabulares y de imágenes con el fín de seleccionar uno de cada uno para sealizar el trabajo del ramo Machine Learning I del Magíster en Data Science de la UDLA.\n",
    "\n",
    "**Integrantes:**\n",
    "- Raúl Urzúa\n",
    "- Adán Marchena"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1040ad6d-535e-4c91-b0d8-f45fa168ab67",
   "metadata": {},
   "source": [
    "## Paso 1: Revisión de datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be12c715",
   "metadata": {},
   "source": [
    "### Revisión de datasets de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f9923",
   "metadata": {},
   "source": [
    "En este notebook se revisarán los datasets para luego seleccionar los tres que se utilizarán en el resto del curso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "618792b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import fsspec\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b8d8db",
   "metadata": {},
   "source": [
    "#### Dataset: Medrxiv-Clustering-s2s\n",
    "**Url:** https://huggingface.co/datasets/mteb/medrxiv-clustering-s2s\n",
    "\n",
    "**Descripción:** Títulos de artículos científicos de MedRxiv en 51 categorías.\n",
    "\n",
    "**Aplicación:** Ideal para modelado de temas o agrupamiento de textos científicos\n",
    "\n",
    "Este dataset forma parte del benchmark Massive Text Embedding Benchmark (MTEB), y está diseñado para evaluar la capacidad de modelos de lenguaje en tareas de agrupamiento semántico (clustering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5edaa38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cómo llamar el dataset desde Hugginface\n",
    "df_medrxiv = pd.read_json(\"hf://datasets/mteb/medrxiv-clustering-s2s/test.jsonl.gz\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d00f1e",
   "metadata": {},
   "source": [
    "**Características**\n",
    "- 2 columnas: \n",
    "  - *sentences (Object):* título de los artículos\n",
    "  - *labels (Object):* área de investigación a la que pertenece el artículo\n",
    "- 17.647 filas\n",
    "- No tiene datos nulos\n",
    "- Dominio: ciencia\n",
    "- Tipo de tarea: Clustering de textos / Modelado de temas.\n",
    "  \n",
    "**Observaciones**\n",
    "\n",
    "Revisando el dataset puedo ver que tiene etiquetas, por lo que no sería muy útil trabajar con ellas para aprendizaje no supervisado. Por otra parte, si solo se utiliza la columna de títulos se podría realizar ejercicios como:\n",
    "- TF-IDF + KMeans → para agrupar artículos por similitud de temas.\n",
    "- Embeddings + PCA o t-SNE → para visualizar los grupos de artículos.\n",
    "- Modelado de temas (LDA) → para descubrir temas latentes automáticamente.\n",
    "\n",
    "Y se podrían utilizar las etiquetas para comparar los clusteres encontrados y evaluar qué tan bien funcionó el modelo aplicado.\n",
    "\n",
    "**Conclusión**\n",
    "\n",
    "Aunque el dataset tiene etiquetas, puede aprovecharse eficazmente para tareas de aprendizaje no supervisado, como agrupamiento temático de textos científicos. Sin embargo, dado que los textos son cortos (solo títulos), puede ser más limitado para representar contextos semánticos amplios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a2ff5b",
   "metadata": {},
   "source": [
    "#### Dataset: arxiv_nlp\n",
    "**Url:** https://huggingface.co/datasets/MaartenGr/arxiv_nlp\n",
    "\n",
    "**Descripción:** Artículos de investigación en NLP. extraídos de arXiv.\n",
    "\n",
    "**Aplicación:** Útil para clustering de documentos académicos.\n",
    "\n",
    "Este dataset recopila publicaciones de investigación del portal arXiv relacionadas con Natural Language Processing (NLP). Contiene tanto títulos como resúmenes (abstracts), lo que permite un análisis semántico más profundo que otros datasets similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9bbc626",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arxiv = pd.read_csv(\"hf://datasets/MaartenGr/arxiv_nlp/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24670fd7-9522-41ac-9875-e8a83c6ad7d7",
   "metadata": {},
   "source": [
    "**Características**\n",
    "- 4 columnas\n",
    "      - *Titles (Object):* título del artículo\n",
    "      - *Abstract (Object):* extracto principal del estudio\n",
    "      - *Years (Int):* año de publicación\n",
    "      - *Categories (Object):* área de investigación a la que pertenece el artículo\n",
    "  - 44.949 filas\n",
    "  - No contiene datos nulos\n",
    "  - Dominio: ciencia / procesamiento de lenguaje natural\n",
    "  - Tipo de tarea: clustering de textos, modelado de temas, análisis temporal de publicaciones\n",
    "\n",
    "**Observaciones**\n",
    "\n",
    "A diferencia del dataset medrxiv, este corpus ofrece textos más largos y contextuales (abstracts), lo que permite aplicar representaciones vectoriales más ricas (por ejemplo, TF-IDF, Word2Vec o embeddings de modelos BERT).\n",
    "Además, la presencia de la variable Year permite explorar la evolución temática de las publicaciones a lo largo del tiempo mediante agrupamiento temporal o visualizaciones de tendencias.\n",
    "\n",
    "**Conclusión**\n",
    "\n",
    "El dataset arxiv_nlp es una excelente opción para tareas de aprendizaje no supervisado en el dominio científico, especialmente para modelado de temas o análisis de similitud entre publicaciones. Su riqueza textual y diversidad temática lo convierten en una fuente sólida para aplicar técnicas de clustering o reducción de dimensionalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787cdd4a-0035-46dc-956b-7d8cdc42267f",
   "metadata": {},
   "source": [
    "#### Dataset: Stack Exchange Topics\n",
    "**Url:** https://www.kaggle.com/competitions/transfer-learning-on-stack-exchange-tags/data\n",
    "\n",
    "**Descripción:** El dataset está compuesto por múltiples subconjuntos temáticos extraídos de la plataforma Kaggle, donde los usuarios realizan preguntas y respuestas sobre distintos temas técnicos y de interés general.\n",
    "Cada subdataset corresponde a una comunidad temática distinta (por ejemplo, biology, cooking, crypto, diy, robotics, travel, etc.).\n",
    "En conjunto, forman un corpus de textos breves con lenguaje natural informal y centrado en la resolución de problemas.\n",
    "\n",
    "**Aplicación:** Ideal para aplicar técnicas de procesamiento de lenguaje natural (NLP), clustering de preguntas por tema, modelado de tópicos (LDA) o análisis de similitud semántica entre comunidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b02a1274-a5bc-4cde-9882-8f5aa4da0d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bio = pd.read_csv(\"texto/Stack Exchange Topics/biology.csv\")\n",
    "df_cook = pd.read_csv(\"texto/Stack Exchange Topics/cooking.csv\")\n",
    "df_cryp = pd.read_csv(\"texto/Stack Exchange Topics/crypto.csv\")\n",
    "df_diy = pd.read_csv(\"texto/Stack Exchange Topics/diy.csv\")\n",
    "df_rob = pd.read_csv(\"texto/Stack Exchange Topics/robotics.csv\")\n",
    "df_ss = pd.read_csv(\"texto/Stack Exchange Topics/sample_submission.csv\")\n",
    "df_test = pd.read_csv(\"texto/Stack Exchange Topics/test.csv\")\n",
    "df_trav = pd.read_csv(\"texto/Stack Exchange Topics/travel.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5936e4a4-2ede-424b-b979-78a0b622584c",
   "metadata": {},
   "source": [
    "**Características generales**\n",
    "\n",
    "- 8 archivos CSV (uno por temática):\n",
    "    - biology.csv\n",
    "    - cooking.csv\n",
    "    - crypto.csv\n",
    "    - diy.csv\n",
    "    - robotics.csv\n",
    "    - sample_submission.csv\n",
    "    - test.csv\n",
    "    - travel.csv\n",
    "- Columnas comunes (pueden variar según archivo):\n",
    "    - id (int): identificador de la publicación\n",
    "    - title (object): título o pregunta del usuario\n",
    "    - body (object): contenido o detalle de la pregunta\n",
    "    - tags (object): etiquetas temáticas asociadas\n",
    "- Cantidad de registros total: depende de la combinación de los 8 archivos (suelen superar las 100.000 filas en total).\n",
    "- Dominio: lenguaje natural / foros de discusión.\n",
    "- No contiene valores nulos significativos.\n",
    "- Tipo de tarea:\n",
    "    - Clustering de textos\n",
    "    - Modelado de temas (LDA, NMF)\n",
    "    - Clasificación de comunidades\n",
    "    - Análisis semántico de preguntas\n",
    "\n",
    "**Observaciones:**\n",
    "\n",
    "Este dataset tiene la particularidad de estar distribuido en múltiples fuentes temáticas, lo que permite diferentes estrategias de análisis:\n",
    "- Se pueden analizar los subdatasets por separado (por ejemplo, agrupar preguntas dentro de biology por similitud de contenido).\n",
    "- O bien unirlos en un solo corpus global, añadiendo una columna “tema” (proveniente del nombre del archivo), para estudiar agrupamientos intertemáticos (por ejemplo, similitudes entre biology y robotics).\n",
    "\n",
    "- Preprocesamiento típico:\n",
    "    - Limpieza de HTML y caracteres especiales.\n",
    "    - Normalización a minúsculas.\n",
    "    - Eliminación de stopwords.\n",
    "    - Tokenización o lematización.\n",
    "    - Vectorización con TF-IDF o embeddings (Word2Vec, BERT).\n",
    "- Métodos posibles:\n",
    "    - TF-IDF + K-Means para agrupar preguntas similares.\n",
    "    - LDA para descubrir temas recurrentes dentro de cada comunidad.\n",
    "    - PCA/t-SNE para visualizar relaciones entre comunidades.\n",
    "\n",
    "**Conclusión:**\n",
    "\n",
    "El dataset Stack Exchange Topics ofrece una excelente base para experimentación en aprendizaje no supervisado.\n",
    "Su estructura multitemática permite tanto el análisis individual de comunidades como la exploración de similitudes entre dominios de conocimiento.\n",
    "A diferencia de los datasets medrxiv y arxiv_nlp, este corpus presenta lenguaje más informal y diverso, lo que lo hace ideal para contrastar modelos entrenados en contextos académicos con datos de lenguaje cotidiano.\n",
    "\n",
    "En síntesis:\n",
    "\n",
    "*Ventajas:* gran volumen, variedad de temas, riqueza léxica, lenguaje natural no técnico.\n",
    "\n",
    "*Desventajas:* textos más ruidosos y desestructurados (mayor trabajo de limpieza).\n",
    "\n",
    "Por su diversidad y tamaño, este dataset puede considerarse una opción sólida como dataset de texto principal, especialmente si se busca aplicar clustering o modelado de temas en lenguaje general."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce6cb72-7936-47e0-afc3-64de2313ad4c",
   "metadata": {},
   "source": [
    "### Revisión de Datasets tabulares\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef92e04-a821-4f0b-9ea1-121a89f47995",
   "metadata": {},
   "source": [
    "#### Dataset: polinaeterna/tabular-benchmark (2 datasets)\n",
    "**Url:** https://huggingface.co/datasets/polinaeterna/tabular-benchmark\n",
    "\n",
    "**Descripción:** Este dataset forma parte del Tabular Benchmark Dataset Collection, que agrupa conjuntos de datos clásicos usados para evaluar modelos en tareas de aprendizaje automático con datos estructurados.\n",
    "Contiene varios subdatasets; en este caso, al cargarlo desde Hugging Face, aparecen dos: **Covertype.csv** y **Higgs.csv**, ambos ampliamente utilizados en investigación y competencias de ML.\n",
    "\n",
    "**Aplicación:** Sirve para realizar análisis exploratorio, reducción de dimensionalidad o aprendizaje no supervisado (por ejemplo, clustering), comparando estructuras y patrones entre variables numéricas y categóricas.\n",
    "También es útil para experimentar con distintos algoritmos en entornos tabulares (KMeans, DBSCAN, PCA, Autoencoders, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "389c38c8-1d4d-465f-bec4-02b47a4e0287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cómo llamar los datasets desde Hugginface\n",
    "df_covertype = pd.read_csv(\"hf://datasets/polinaeterna/tabular-benchmark/clf_cat/covertype.csv\")\n",
    "df_higgs = pd.read_csv(\"hf://datasets/polinaeterna/tabular-benchmark/clf_num/Higgs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0085c7-a892-4a87-a448-aa8770b2efb0",
   "metadata": {},
   "source": [
    "**Subdatasets**\n",
    "\n",
    "1. Covertype\n",
    "- Descripción:* Datos de cobertura forestal en EE. UU. recopilados por el U.S. Forest Service.\n",
    "Cada registro representa un área de bosque con información topográfica y de suelo, y la variable objetivo indica el tipo de cobertura forestal.\n",
    "- Características:\n",
    "    - Filas: 423.680\n",
    "    - Columnas: 55 (todas numéricas)\n",
    "    - No hay valores nulos\n",
    "- Dominio: Medio ambiente / geografía\n",
    "- Aplicaciones posibles:\n",
    "    - Clustering para descubrir regiones con características similares.\n",
    "    - Reducción de dimensionalidad (PCA, t-SNE) para visualizar los patrones entre tipos de terreno.\n",
    "    - Modelado de correlaciones entre variables ambientales.\n",
    "\n",
    "2. Higgs\n",
    "- Descripción: Datos simulados del experimento del CERN sobre detección del bosón de Higgs.\n",
    "Cada registro representa un evento con 28 variables físicas (energías, momentos, ángulos, etc.), usadas para distinguir entre eventos del Higgs y ruido de fondo.\n",
    "- Características:\n",
    "    - Filas: 940.160\n",
    "    - Columnas: 25 (todas numéricas)\n",
    "    - No contiene valores nulos\n",
    "    - Dominio: Física de partículas\n",
    "- Aplicaciones posibles:\n",
    "    - Clustering para identificar patrones o grupos de eventos similares.\n",
    "    - Reducción de dimensionalidad (PCA, UMAP) para visualizar la estructura del espacio de eventos.\n",
    "    - Ejercicio de análisis comparativo entre eventos reales y simulados.\n",
    "\n",
    "**Observaciones**\n",
    "- Aunque ambos datasets incluyen etiquetas, pueden ignorarse para enfocarse en aprendizaje no supervisado.\n",
    "- El dataset Higgs es más adecuado si quieres explorar datasets numéricos grandes con cierta complejidad matemática.\n",
    "- Covertype es más manejable y tiene interpretabilidad más clara (relaciones geográficas y ambientales).\n",
    "\n",
    "**Conclusión**\n",
    "\n",
    "La colección Tabular Benchmark permite realizar experimentos de aprendizaje no supervisado con datos reales y multidimensionales.\n",
    "Ambos subdatasets son sólidos candidatos, pero:\n",
    "- Covertype destaca por su interpretabilidad y estructura equilibrada.\n",
    "- Higgs por su volumen y desafío computacional moderado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4796781d-3422-464b-bc5e-bc160eced288",
   "metadata": {},
   "source": [
    "#### Dataset: Analyzing Student Academic Trends\n",
    "**Url:** https://www.kaggle.com/datasets/saadaliyaseen/analyzing-student-academic-trends\n",
    "\n",
    "**Descripción:** Este conjunto de datos contiene información académica de 200 estudiantes. Incluye detalles sobre sus hábitos de estudio, duración del sueño, asistencia, rendimiento académico anterior y calificaciones de los exámenes finales. Los datos se pueden utilizar para analizar los factores que influyen en el rendimiento en los exámenes e identificar patrones en los resultados del aprendizaje de los estudiantes.\n",
    "\n",
    "**Aplicación:** \n",
    "- Predecir estudiantes en riesgo de bajo rendimiento\n",
    "- Identificar factores clave para el éxito académico\n",
    "- Segmentación de estudiantes para intervenciones personalizadas\n",
    "- Análisis de impacto de diferentes hábitos de estudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f50c47f-2870-4b3d-8ba7-889382b12908",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students = pd.read_csv(\"tabulares/student_exam_scores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c260930-adec-4345-9661-72ece4a412cf",
   "metadata": {},
   "source": [
    "**Características**\n",
    "- 6 columnas\n",
    "    - Una columna de tipo Object que representa el id del estudiante\n",
    "    - 5 columnas numéricas (4 float, 1 int)\n",
    "- 200 filas\n",
    "- No contiene datos nulos\n",
    "- Dominio: análisis estudiantil\n",
    "- Tipo de tarea:\n",
    "    - Random Forest, XGBoost para clasificación\n",
    "    - Regresión lineal para predicción de notas\n",
    "    - K-means para clustering\n",
    "    - Árboles de decisión para interpretabilidad\n",
    "\n",
    "**Observaciones**\n",
    "\n",
    "El dataset tiene una buena estructura, con datos bien organizados y contiene una temática interesante, de la que se pueden obtener casos interesantes de estudio. No contiene variables categóricas, lo que lo vuelve especialmente óptimo para aprendizaje no supervizado en el que se pueden aplicar técnicas como Clustering: Agrupar estudiantes por patrones de estudio/sueño/rendimiento, o PCA: Reducir dimensionalidad y visualizar patrones.\n",
    "\n",
    "**Conclusión**\n",
    "\n",
    "Es un dataset muy adecuado para empezar con machine learning, especialmente si se está interesado en educación analytics o se busca practicar con datos del mundo real. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224f0a19-2da6-4711-8358-f57106d16b6c",
   "metadata": {},
   "source": [
    "#### Dataset: Breast_cancer_dataset\n",
    "**Url:** https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset\n",
    "\n",
    "**Descripción:** este dataset contiene información sobre las dimensiones de tumores alojados en las mamas femeninas (radio, textura, perímetro, etc.), además de un target de diagnóstico (M o B). Es uno de los datasets más utilizados en la literatura de ML y ha ayudado a avanzar en técnicas de diagnóstico temprano de cáncer.\n",
    "\n",
    "**Aplicación:** Diagnóstico asistido por ML en medicina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25b31fc9-fa37-4c99-9ea5-4a99f4b129cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_breast = pd.read_csv(\"tabulares/Breast_cancer_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dc4bb3-0176-4173-ad59-a61ac87687e8",
   "metadata": {},
   "source": [
    "**Características**\n",
    "\n",
    "- 569 filas\n",
    "- 32 columnas\n",
    "    - Contiene un target: columna `diagnosis` con los valores M (Maligno) y B (Benigno)\n",
    "    - Las demás columnas son numéricas (una int y 30 float)\n",
    "    - Contiene una columna vacía. las demás no presentan datos nulos\n",
    "    - Dominio: medicina/oncología\n",
    "    - Tipo de tarea:\n",
    "      - SVM\n",
    "      - Random Forest\n",
    "      - Logistic Regression\n",
    "      - Neural Networks\n",
    "\n",
    "**Observaciones**\n",
    "\n",
    "El dataset presenta un problema de clasificación binaria, pero aplicaría lo mismo que para los demás; trabajar sin esa columna. Por otra parte presenta varias ventajas, sobretodo en el ámbito de la salud. Este dataset nos permitiría eventualmente aportar un granito de arena a la lucha contra el cáncer.\n",
    "También tiene un gran valor educativo:\n",
    "- Excelente para practicar clasificación médica\n",
    "- Ideal para aprender sobre importancia de características\n",
    "- Buen caso para normalización de datos (escalas diferentes)\n",
    "- Demostración de ML con impacto social \n",
    "\n",
    "**Conclusión**\n",
    "\n",
    "A pesar de la clasificación binaria que posee, el dataset tiene un gran potencial para trabajar con él, sobretodo por la importancia que podría significar un hagazgo relevante para la salud, en especial de las mujeres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356f1fd3-629f-4ed9-ac4e-27fb4432b149",
   "metadata": {},
   "source": [
    "### Revisión de Datasets de imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46688fa5-cccd-4896-95cc-4722c92115c9",
   "metadata": {},
   "source": [
    "#### Agriculture crop images\n",
    "**Url:** https://www.kaggle.com/datasets/aman2000jaiswal/agriculture-crop-images\n",
    "\n",
    "**Descripción:** Conjunto de imágenes agrícolas con diferentes tipos de cultivos (trigo, arroz, maíz, algodón, entre otros).\n",
    "El dataset fue originalmente diseñado para clasificación supervisada de cultivos, pero puede utilizarse en contextos no supervisados para explorar similitudes visuales entre especies vegetales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbcf000-a7bb-48a3-9339-f3982a348dba",
   "metadata": {},
   "source": [
    "**Características**\n",
    "\n",
    "- Total de imágenes: ~3.200\n",
    "- Formato: .jpg\n",
    "- Resolución promedio: 256×256 píxeles\n",
    "- Contiene carpetas por tipo de cultivo (pueden omitirse para análisis no supervisado)\n",
    "- Dominio: agricultura / visión computacional\n",
    "\n",
    "**Aplicaciones posibles**\n",
    "\n",
    "- Clustering para agrupar imágenes según texturas o colores predominantes.\n",
    "- Reducción de dimensionalidad con PCA o t-SNE para visualizar relaciones entre tipos de cultivos.\n",
    "- Evaluación de representaciones visuales en entornos naturales.\n",
    "\n",
    "**Conclusión**\n",
    "\n",
    "Dataset adecuado para aplicar aprendizaje no supervisado en imágenes del entorno natural.\n",
    "Permite estudiar la capacidad de los modelos para distinguir patrones visuales asociados a diferentes especies vegetales sin usar etiquetas explícitas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1376f6a5-f1cb-4b4b-91ad-155dfb7cf431",
   "metadata": {},
   "source": [
    "#### CT Medical Images\n",
    "**Url:** https://www.kaggle.com/datasets/kmader/siim-medical-images\n",
    "\n",
    "**Descripción:** Colección de imágenes médicas provenientes de la Sociedad de Informática en Imágenes Médicas (SIIM). Incluye estudios radiológicos y tomográficos en formato DICOM, posteriormente convertidos a imágenes estándar.\n",
    "El dataset fue diseñado para tareas de diagnóstico automático, pero puede utilizarse para aprendizaje no supervisado orientado a la agrupación de imágenes médicas según características morfológicas o anatómicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4989af8e-917b-489c-8217-620783c6eec1",
   "metadata": {},
   "source": [
    "**Características**\n",
    "\n",
    "- Total de imágenes: ~12.000\n",
    "- Formato: .jpg o .png (derivado de DICOM)\n",
    "- Contenido: radiografías de tórax y otras regiones anatómicas\n",
    "- Resolución variable\n",
    "- Algunas imágenes presentan etiquetas diagnósticas, pero pueden omitirse para análisis no supervisado\n",
    "- Dominio: medicina / imágenes biomédicas\n",
    "\n",
    "**Aplicaciones posibles**\n",
    "\n",
    "- Clustering para descubrir patrones visuales en imágenes médicas sin usar etiquetas.\n",
    "- Reducción de dimensionalidad con autoencoders o PCA para analizar similitudes entre estudios.\n",
    "- Preprocesamiento para segmentación o detección de anomalías sin supervisión.\n",
    "\n",
    "**Conclusión**\n",
    "\n",
    "Dataset relevante para experimentos de agrupamiento o representación no supervisada en el ámbito médico.\n",
    "Su complejidad y naturaleza visual homogénea permiten evaluar la sensibilidad de modelos no supervisados a pequeñas variaciones estructurales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77f854d-8c30-4558-a6e7-d8d9dac9e992",
   "metadata": {},
   "source": [
    "#### Small image dataset for unsupervised clustering\n",
    "**Url:** https://www.kaggle.com/datasets/heavensky/image-dataset-for-unsupervised-clustering\n",
    "\n",
    "**Descripción:** Conjunto de imágenes recopiladas con el propósito de realizar tareas de aprendizaje no supervisado, específicamente clustering.\n",
    "Contiene imágenes de distintos objetos y escenas variadas, sin etiquetas predefinidas, lo que lo convierte en un recurso ideal para ejercicios de agrupamiento y reducción de dimensionalidad en el dominio visual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a3a4e-81cc-413c-9729-f67b490a1e43",
   "metadata": {},
   "source": [
    "**Características**\n",
    "\n",
    "- Total de imágenes: aproximadamente 8.000\n",
    "- Formato: .jpg\n",
    "- Tamaño promedio: 128×128 píxeles\n",
    "- Categorías: variadas (paisajes, animales, objetos, personas, entre otros)\n",
    "- No contiene etiquetas (dataset puramente no supervisado)\n",
    "- Dominio: visión por computadora general\n",
    "\n",
    "**Aplicaciones posibles**\n",
    "\n",
    "- Clustering de imágenes mediante extracción de features con redes preentrenadas (por ejemplo, VGG16 o ResNet50).\n",
    "- Reducción de dimensionalidad con PCA, t-SNE o UMAP para visualizar agrupamientos.\n",
    "- Evaluación cualitativa de similitud visual entre imágenes.\n",
    "\n",
    "**Conclusión**\n",
    "\n",
    "Dataset apropiado para analizar la efectividad de técnicas no supervisadas en imágenes sin anotaciones.\n",
    "Su diversidad lo hace útil para pruebas exploratorias y comparación de representaciones visuales basadas en features profundas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411fca8d-f6f4-4c0c-bb2a-4b462bcd0cf3",
   "metadata": {},
   "source": [
    "## Paso 2: Selección de trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595dee7b-257d-45cf-bce8-b5e003323371",
   "metadata": {},
   "source": [
    "### Dataset de Texto\n",
    "Arxiv NLP (MaartenGr)\n",
    "https://huggingface.co/datasets/MaartenGr/arxiv_nlp\n",
    "\n",
    "**Motivo:***\n",
    "\n",
    "Tiene suficiente contenido textual para un análisis semántico real (modelado de temas, embeddings, clustering). Además, su estructura (título + abstract) permite comparar resultados y obtener visualizaciones interpretables. Es más “limpio” y académico que Stack Exchange y más rico que MedRxiv.\n",
    "\n",
    "**Resumen:**\n",
    "\n",
    "El dataset contiene casi 45.000 artículos académicos del dominio de procesamiento del lenguaje natural (NLP) obtenidos desde arXiv. Cada registro incluye el título, resumen, año y categoría temática del artículo, ofreciendo una muestra representativa de la investigación científica reciente en este campo.\n",
    "\n",
    "**Posibles problemas del mundo real:**\n",
    "\n",
    "Podría utilizarse para detectar automáticamente los temas emergentes en investigación NLP, identificar áreas con mayor crecimiento, o agrupar artículos similares para facilitar la búsqueda y organización de literatura científica sin depender de etiquetas preexistentes.\n",
    "\n",
    "**Tipo de aprendizaje no supervisado:**\n",
    "\n",
    "Modelado de temas con LDA (Latent Dirichlet Allocation) o clustering con embeddings + K-Means. LDA permitiría descubrir temas latentes dentro de los abstracts, mientras que los embeddings combinados con K-Means podrían identificar grupos de artículos con lenguaje similar o enfoques metodológicos parecidos.\n",
    "\n",
    "**Desafíos potenciales:**\n",
    "\n",
    "El tamaño y la longitud variable de los textos pueden aumentar la complejidad computacional. Además, los abstracts suelen contener vocabulario técnico y siglas que requieren una limpieza cuidadosa. Puede haber redundancia entre artículos muy similares, y el número óptimo de temas o clusters no es trivial de determinar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df59742-ef4c-4365-84a3-c90e707c6d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como llamar el dtaset desde Hugginface\n",
    "df_arxiv = pd.read_csv(\"hf://datasets/MaartenGr/arxiv_nlp/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d98e77-f788-465b-a27a-539bcc49dc49",
   "metadata": {},
   "source": [
    "### Dataset Tabular\n",
    "\n",
    "Covertype\n",
    "https://huggingface.co/datasets/polinaeterna/tabular-benchmark\n",
    "\n",
    "**Motivo:**\n",
    "Es lo bastante grande (~420 mil filas) para mostrar técnicas de clustering y reducción de dimensionalidad, con múltiples variables numéricas reales. Permite aplicar PCA, KMeans y DBSCAN de forma significativa, y tiene buena interpretabilidad sin ser un caso “típico” como el Titanic o Iris.\n",
    "\n",
    "**Resumen:**\n",
    "El dataset Covertype contiene 423.680 filas y 55 columnas que describen características ambientales y topográficas de parcelas de terreno en EEUU (elevación, pendiente, suelo, sombras, etc.). El objetivo original era predecir el tipo de cobertura forestal, pero aquí se puede usar sin etiquetas para análisis exploratorio y clustering ambiental.\n",
    "\n",
    "**Posibles problemas del mundo real:**\n",
    "Puede aplicarse para identificar regiones con características ecológicas similares, realizar segmentaciones ambientales o descubrir patrones naturales en los tipos de bosques según las variables geográficas y climáticas. También podría servir para detectar regiones atípicas o con condiciones ambientales inusuales.\n",
    "\n",
    "**Tipo de aprendizaje no supervisado:**\n",
    "Clustering (K-Means, DBSCAN o Gaussian Mixture Models) para agrupar regiones similares según sus condiciones geográficas, y reducción de dimensionalidad (PCA o t-SNE) para visualizar las relaciones entre las variables ambientales. Estos métodos permitirían descubrir agrupamientos naturales sin depender de las etiquetas del tipo de bosque.\n",
    "\n",
    "**Desafíos potenciales:**\n",
    "\n",
    "La gran cantidad de variables numéricas y categóricas requiere una buena normalización y codificación. Algunas características pueden tener alta correlación, lo que puede distorsionar el clustering. Además, el tamaño del dataset puede implicar una alta demanda de memoria y tiempo de cómputo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd0e602-ea46-4ba3-b039-1f781d00c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cómo llamar el datasets desde Hugginface\n",
    "df_covertype = pd.read_csv(\"hf://datasets/polinaeterna/tabular-benchmark/clf_cat/covertype.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8370089-f7ed-484a-b565-f2ad5a0c0087",
   "metadata": {},
   "source": [
    "### Dataset de Imagénes\n",
    "Image Dataset for Unsupervised Clustering\n",
    "https://www.kaggle.com/datasets/heavensky/image-dataset-for-unsupervised-clustering\n",
    "\n",
    "**Motivo:**\n",
    "Es el único de los tres creado explícitamente para aprendizaje no supervisado. Te permite aplicar desde extracción de características con CNNs preentrenadas (como ResNet o VGG16) hasta clustering o reducción de dimensionalidad (PCA, t-SNE). Es directo, limpio y cumple el objetivo del trabajo sin requerir anotaciones médicas o agrícolas.\n",
    "\n",
    "**Resumen:**\n",
    "El dataset incluye miles de imágenes de cultivos agrícolas tomadas en distintas condiciones, con variaciones en iluminación, ángulo y fondo. Cada carpeta representa una especie vegetal distinta (por ejemplo, arroz, maíz, trigo, etc.), aunque el objetivo puede abordarse sin usar dichas etiquetas explícitamente.\n",
    "\n",
    "**Posibles problemas del mundo real:**\n",
    "Podría utilizarse para clasificar cultivos automáticamente, detectar similitudes entre especies o identificar tipos de plantas desconocidas en imágenes sin etiquetar. También sería útil en tareas de monitoreo agrícola o detección de anomalías en cultivos.\n",
    "\n",
    "**Tipo de aprendizaje no supervisado:**\n",
    "Modelos de autoencoders convolucionales o clustering de embeddings de imágenes (K-Means, DBSCAN) para agrupar imágenes visualmente similares. Estos métodos permiten representar las imágenes en un espacio latente donde la similitud semántica es más evidente.\n",
    "\n",
    "**Desafíos potenciales:**\n",
    "Las imágenes pueden tener tamaños y resoluciones diferentes, lo que exige un preprocesamiento intensivo. El número de muestras por clase puede estar desbalanceado y el entrenamiento de modelos de visión no supervisados es computacionalmente costoso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84f06b-60b2-4d8a-a859-1efdadace563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv-6)",
   "language": "python",
   "name": "venv-6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
