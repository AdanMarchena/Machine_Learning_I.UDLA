{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4034c3d-c104-43b2-91ec-5302cbdf6bb7",
   "metadata": {},
   "source": [
    "# Propuesta Dataset texto\n",
    "\n",
    "**Datasets seleccionado:** Arxiv NLP (MaartenGr)\n",
    "\n",
    "**URL:** https://huggingface.co/datasets/MaartenGr/arxiv_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b4eb0b-218b-4c96-af8f-ad226803604f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset cargado correctamente\n",
      "Filas: 44949, Columnas: 4\n",
      "                                              Titles  \\\n",
      "0  Introduction to Arabic Speech Recognition Usin...   \n",
      "1  Arabic Speech Recognition System using CMU-Sph...   \n",
      "2  On the Development of Text Input Method - Less...   \n",
      "3  Network statistics on early English Syntax: St...   \n",
      "4  Segmentation and Context of Literary and Music...   \n",
      "\n",
      "                                           Abstracts  Years  \\\n",
      "0    In this paper Arabic was investigated from t...   2007   \n",
      "1    In this paper we present the creation of an ...   2007   \n",
      "2    Intelligent Input Methods (IM) are essential...   2007   \n",
      "3    This paper includes a reflection on the role...   2007   \n",
      "4    We test a segmentation algorithm, based on t...   2007   \n",
      "\n",
      "                 Categories  \n",
      "0  Computation and Language  \n",
      "1  Computation and Language  \n",
      "2  Computation and Language  \n",
      "3  Computation and Language  \n",
      "4  Computation and Language  \n"
     ]
    }
   ],
   "source": [
    "# Librerías\n",
    "import pandas as pd\n",
    "\n",
    "# URL directa al CSV en Hugging Face\n",
    "url = \"https://huggingface.co/datasets/MaartenGr/arxiv_nlp/resolve/main/data.csv\"\n",
    "\n",
    "# Cargar directamente en un DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Mostrar información básica\n",
    "print(\"✅ Dataset cargado correctamente\")\n",
    "print(f\"Filas: {df.shape[0]}, Columnas: {df.shape[1]}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5a755-9ac8-4fac-944e-7b226a04957a",
   "metadata": {},
   "source": [
    "**1. ¿Qué problema concreto resolverás? ¿Por qué es relevante?**\n",
    "\n",
    "Para comenzar, este dataset contiene metadatos y resúmenes de artículos de arXiv (una plataforma de investigación científica).<br><br>\n",
    "El problema concreto que resolvería es la clasificación y análisis de artículos científicos según su contenido.<br>\n",
    "Para aquello principalmente hay que buscar resolver, cómo entender, organizar y clasificar automáticamente estos textos mediante técnicas de Procesamiento del Lenguaje Natural (NLP).<br>\n",
    "\n",
    "Por qué es relevante?\n",
    "\n",
    "1. Volumen creciente de investigación: Al haber miles de papers nuevos publicad por día en arXiv. Clasificarlos y analizarlos manualmente es inviable.\n",
    "2. Automatización inteligente: Permitiría entrenar modelos como, la clasificación de artículos por tema, la generación de resúmenes automátizados, la detección de similitudes entre trabajos y la busqueda de tendencias emergentes en la investigación científica.\n",
    "3. Aplicaciones prácticas: la creación de motores de recomendación de papers, sistemas de búsqueda semántica (por contenido, no solo por palabras claves) y el análisis de tendencias en ciencia (por ejemplo, detectar áreas de rápido crecimiento)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78fd2d8-6a10-4056-bb14-b9565f4537d4",
   "metadata": {},
   "source": [
    "**¿Qué tipo de modelo de aprendizaje no supervisado usarás inicialmente? escoger al menos 2 vistos en clase y 2 no vistos en clase? Explicar teóricamente como funciona el modelo y los algoritmos usados por cada método.** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af8a09a-0529-4c49-9a1b-a7a9a28e0d7c",
   "metadata": {},
   "source": [
    "**¿Qué métrica de evaluación utilizarás y por qué?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4f8431-9e7e-48ef-9555-6be45c010297",
   "metadata": {},
   "source": [
    "**¿Quiénes serían los usuarios o beneficiarios del modelo?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae63f8-d2d9-491a-992f-2ecdba4d5234",
   "metadata": {},
   "source": [
    "**¿Qué esperas lograr con tu modelo? (clasificar, predecir, segmentar, etc.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e701298-5679-4a5c-9bdd-eb2890362fbe",
   "metadata": {},
   "source": [
    "**¿Qué herramientas planeas usar? (PyTorch, TensorFlow, Keras, etc.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a99a91-e3f9-452a-865b-f0dd4e66d4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
