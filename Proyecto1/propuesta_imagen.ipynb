{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3becba8-b4bf-449b-ac50-a16d8109e230",
   "metadata": {},
   "source": [
    "# Propuesta Dataset Imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc5d929-4023-4c69-8c51-2cab04818632",
   "metadata": {},
   "source": [
    "**Datasets seleccionado:** Unsupervised Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ab2ee0-acbd-4454-9160-02548f1ad6d3",
   "metadata": {},
   "source": [
    "**URL:** https://www.kaggle.com/datasets/heavensky/image-dataset-for-unsupervised-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f2a5640-c80a-4740-9412-3f6e2121f145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.13-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\mlcc\\miniconda3\\envs\\p_datos\\lib\\site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\mlcc\\miniconda3\\envs\\p_datos\\lib\\site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\mlcc\\miniconda3\\envs\\p_datos\\lib\\site-packages (from kagglehub) (2.32.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mlcc\\miniconda3\\envs\\p_datos\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mlcc\\miniconda3\\envs\\p_datos\\lib\\site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mlcc\\miniconda3\\envs\\p_datos\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mlcc\\miniconda3\\envs\\p_datos\\lib\\site-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mlcc\\miniconda3\\envs\\p_datos\\lib\\site-packages (from requests->kagglehub) (2025.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\mlcc\\miniconda3\\envs\\p_datos\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading kagglehub-0.3.13-py3-none-any.whl (68 kB)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f6bbdef-d199-4c91-a9dc-4ca47ad555c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mlcc\\miniconda3\\envs\\p_datos\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/heavensky/image-dataset-for-unsupervised-clustering?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 6.63M/6.63M [00:06<00:00, 1.07MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\mlcc\\.cache\\kagglehub\\datasets\\heavensky\\image-dataset-for-unsupervised-clustering\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"heavensky/image-dataset-for-unsupervised-clustering\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bac4d56-cae4-4afd-bd46-dae1dd984864",
   "metadata": {},
   "source": [
    "## Mostrar el directorio con las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8c78f43-1e2d-4b3b-8fbc-b3f6f8a3dcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/\n",
      "│   images/\n",
      "│   │   asparagus-g4c4164115_640.jpg\n",
      "│   │   beanie-g4c423e47b_640.jpg\n",
      "│   │   bibimbap-gf29abdbf1_640.jpg\n",
      "│   │   cat-g0052cc4e9_640.jpg\n",
      "│   │   cat-g0fcd844a4_640.jpg\n",
      "│   │   cat-g11b1f4535_640.jpg\n",
      "│   │   cat-g4ae5d18aa_640.jpg\n",
      "│   │   cat-g4fe5d8c20_640.jpg\n",
      "│   │   cat-g6052b543b_640.jpg\n",
      "│   │   cat-ga3a48da6e_640.jpg\n",
      "│   │   cat-gaf654b3a3_640.jpg\n",
      "│   │   cat-gf324dae69_640.jpg\n",
      "│   │   cave-g68bd31d20_640.jpg\n",
      "│   │   champon-g31fa88e14_640.jpg\n",
      "│   │   chicken-soup-g76231cf36_640.jpg\n",
      "│   │   child-g8f11ee379_640.jpg\n",
      "│   │   children-g13a48a038_640.jpg\n",
      "│   │   couple-g0b2ee91be_640.jpg\n",
      "│   │   dog-g0973e56d5_640.jpg\n",
      "│   │   dog-g7dcd325a6_640.jpg\n",
      "│   │   dog-g904e7432d_640.jpg\n",
      "│   │   dog-gaeaae353d_640.jpg\n",
      "│   │   elderly-woman-gf7899b581_640.jpg\n",
      "│   │   family-g2ea85c1e0_640.jpg\n",
      "│   │   family-g441413fcc_640.jpg\n",
      "│   │   family-gb1f51caae_640.jpg\n",
      "│   │   family-gc23518eae_640.jpg\n",
      "│   │   family-gcf1c70a98_640.jpg\n",
      "│   │   family-gdcb5d5e9a_640.jpg\n",
      "│   │   family-ge3ec489c4_640.jpg\n",
      "│   │   father-g4f347136d_640.jpg\n",
      "│   │   father-g7328a944c_640.jpg\n",
      "│   │   food-g091033cad_640.jpg\n",
      "│   │   food-g554ae271b_640.jpg\n",
      "│   │   fried-rice-g8b4a54246_640.jpg\n",
      "│   │   friends-ge08bcacfd_640.jpg\n",
      "│   │   girl-g6a909b6e4_640.jpg\n",
      "│   │   girl-gb9f87fafe_640.jpg\n",
      "│   │   grandmother-g010adc60b_640.jpg\n",
      "│   │   grandparents-g83fa83a69_640.jpg\n",
      "│   │   hamburger-gafdf3eadc_640.jpg\n",
      "│   │   in-love-g33a19ee34_640.jpg\n",
      "│   │   kid-gfcb80c8d7_640.jpg\n",
      "│   │   kitten-gfa0ebce93_640.jpg\n",
      "│   │   mama-gc2e107d95_640.jpg\n",
      "│   │   man-g3f074f028_640.jpg\n",
      "│   │   man-g6d33fb453_640.jpg\n",
      "│   │   man-g80cf5109d_640.jpg\n",
      "│   │   man-gab0982e39_640.jpg\n",
      "│   │   man-gb4440ab53_640.jpg\n",
      "│   │   mandu-g79128b0db_640.jpg\n",
      "│   │   mother-gea63914a7_640.jpg\n",
      "│   │   nem-gdf1e9c93c_640.jpg\n",
      "│   │   octopus-desktop-gab5dc2902_640.jpg\n",
      "│   │   old-couple-ge9a180ac0_640.jpg\n",
      "│   │   pasta-ge05c4d3a5_640.jpg\n",
      "│   │   people-g4cbd1dbc4_640.jpg\n",
      "│   │   people-gb066aa303_640.jpg\n",
      "│   │   person-gda5ec2e25_640.jpg\n",
      "│   │   pizza-gbc9c3ad3c_640.jpg\n",
      "│   │   plate-gc7cadb9f6_640.jpg\n",
      "│   │   puppy-g0235e261e_640.jpg\n",
      "│   │   puppy-g7bfbbf1d9_640.jpg\n",
      "│   │   puppy-ge9d742e37_640.jpg\n",
      "│   │   sad-g31db419ca_640.jpg\n",
      "│   │   sad-g7e6ada8a4_640.jpg\n",
      "│   │   salad-bar-g5de038197_640.jpg\n",
      "│   │   salad-g8aa52b764_640.jpg\n",
      "│   │   selfie-g46d822e69_640.jpg\n",
      "│   │   selfie-g626251ddd_640.jpg\n",
      "│   │   sibling-g1003a623b_640.jpg\n",
      "│   │   stairs-g5b4e7ea44_640.jpg\n",
      "│   │   sushi-g108a16441_640.jpg\n",
      "│   │   sushi-g47b8ca32e_640.jpg\n",
      "│   │   terrier-g5cb29fa82_640.jpg\n",
      "│   │   tteokbokki-gcbb446eda_640.jpg\n",
      "│   │   umbrella-g4e69f144a_640.jpg\n",
      "│   │   woman-g40964425a_640.jpg\n",
      "│   │   women-girl-gf81cdab46_640.jpg\n",
      "│   │   young-woman-g0ceffcc6e_640.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def mostrar_arbol(path, prefijo=\"\"):\n",
    "    print(prefijo + os.path.basename(directorio) + \"/\")\n",
    "    contenido = os.listdir(path)\n",
    "    for i, nombre in enumerate(contenido):\n",
    "        ruta = os.path.join(path, nombre)\n",
    "        if os.path.isdir(ruta):\n",
    "            mostrar_arbol(ruta, prefijo + \"│   \")\n",
    "        else:\n",
    "            print(prefijo + \"│   \" + nombre)\n",
    "\n",
    "# Ruta del directorio que quieres mostrar\n",
    "directorio = \"data/images\"\n",
    "mostrar_arbol(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b61f939-2adc-4091-9ddb-82e5ccdf6e0c",
   "metadata": {},
   "source": [
    "## Ejemplo de imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643d0aa-5fac-4935-b821-1c65c5eaf248",
   "metadata": {},
   "source": [
    "A continuación mostrare un ejemplo de imagen del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13312a09-0d48-4ffe-b04a-e3eb9de20c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://storage.googleapis.com/kagglesdsdata/datasets/2588649/4418848/photos_no_class/asparagus-g4c4164115_640.jpg?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20251014%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20251014T163256Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=a073a497a4010e23013ae75e4a5540943f0edbe001d5621edf0f2c6235549524ae424f97626c393452b88014819583167258d5f8fa527ca2015ec8e2adac7c728bccf48da8a19064b7cc1a0529e6b0bbf31f95d540a106dfae599cddae654a0c1a5bcae1e5a60cbf7d691ede30d0298fc3447d62bdea33064e71a28d6f551d169efdca0eab78edb07bc250944d28d3fe677f82ad4f1e9b1a9959f45ed91c7a9ccc2975e6d735eb63e3b0ed07177a7cdbe521a578a3422c181532341d56dddb8fbc12b6e2eb482e2c452e04f0b99c856511e9129ee78c3549c3be3d0e9418732d11c90398dabfa4c7d6998b26a260786c74aad4db16385750eba6e20f54e309c2\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# biblioteca\n",
    "from IPython.display import Image, display\n",
    "\n",
    "url = \"https://storage.googleapis.com/kagglesdsdata/datasets/2588649/4418848/photos_no_class/asparagus-g4c4164115_640.jpg?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20251014%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20251014T163256Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=a073a497a4010e23013ae75e4a5540943f0edbe001d5621edf0f2c6235549524ae424f97626c393452b88014819583167258d5f8fa527ca2015ec8e2adac7c728bccf48da8a19064b7cc1a0529e6b0bbf31f95d540a106dfae599cddae654a0c1a5bcae1e5a60cbf7d691ede30d0298fc3447d62bdea33064e71a28d6f551d169efdca0eab78edb07bc250944d28d3fe677f82ad4f1e9b1a9959f45ed91c7a9ccc2975e6d735eb63e3b0ed07177a7cdbe521a578a3422c181532341d56dddb8fbc12b6e2eb482e2c452e04f0b99c856511e9129ee78c3549c3be3d0e9418732d11c90398dabfa4c7d6998b26a260786c74aad4db16385750eba6e20f54e309c2\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2845b4-cbff-4335-bcd9-5bf5027dce76",
   "metadata": {},
   "source": [
    "**¿Qué problema concreto resolverás? ¿Por qué es relevante?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06166c1c-4cd7-4228-903c-6c2c32ee7876",
   "metadata": {},
   "source": [
    "El problema concreto que se busca resolver con este proyecto es organizar y segmentar automáticamente un gran conjunto de imágenes sin etiquetas mediante técnicas de clustering no supervisado. Dado que el dataset consiste en cientos o miles de imágenes, resulta impracticable clasificarlas manualmente.<br> \n",
    "Además, la segmentación automática permite descubrir patrones visuales, agrupar imágenes similares y facilitar su análisis o búsqueda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7d2e38-40ab-46a0-bd88-06a08d53157a",
   "metadata": {},
   "source": [
    "Esto es relevante porque muchas aplicaciones modernas, como búsqueda de imágenes, categorización de productos, análisis de medios o gestión de bibliotecas visuales.<br> \n",
    "Ademas requieren procesar grandes volúmenes de datos visuales sin depender de etiquetas previas, optimizando tiempo, recursos y la capacidad de extraer conocimiento útil de manera eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a35b46-0cbf-4279-84cc-d09abe98542c",
   "metadata": {},
   "source": [
    "**¿Qué tipo de modelo de aprendizaje no supervisado usarás inicialmente? escoger al menos 2 vistos en clase y 2 no vistos en clase? Explicar teóricamente como funciona el modelo y los algoritmos usados por cada método.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9a6cf3-1666-463b-922e-a27e00040715",
   "metadata": {},
   "source": [
    "Para el análisis del dataset Arxiv NLP se propone aplicar cuatro modelos de aprendizaje no supervisado, combinando dos métodos vistos en clase y dos no vistos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df981d58-9ce7-49db-99aa-924d075b1514",
   "metadata": {},
   "source": [
    "**Modelos vistos en clase**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdfca50-e868-4fcb-bd5b-374eb37a6ce0",
   "metadata": {},
   "source": [
    "**K-means**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02a3bd7-bee1-4adc-a7bc-5efb148bca53",
   "metadata": {},
   "source": [
    "- K-means aplicado a un dataset de imágenes funciona transformando primero cada imagen en un vector numérico que capture sus características visuales, como píxeles normalizados, histogramas de color o embeddings extraídos de redes neuronales preentrenadas (por ejemplo ResNet o VGG).\n",
    "- Luego, el algoritmo inicia con un número K de centroides aleatorios y asigna cada imagen al centro más cercano según una medida de distancia (como euclidiana o coseno).\n",
    "- Después, recalcula iterativamente los centroides como el promedio de las imágenes asignadas a cada clúster hasta que las asignaciones se estabilizan. El resultado es un agrupamiento de imágenes similares, lo que permite segmentar grandes colecciones sin etiquetas y descubrir patrones o categorías visuales automáticamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e755eef2-362d-45c5-aa96-3d890bd0665e",
   "metadata": {},
   "source": [
    "**PCA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d33dc9-31a0-4267-a3cb-9bee8238fdda",
   "metadata": {},
   "source": [
    "El PCA (Análisis de Componentes Principales) aplicado a un dataset de imágenes sirve para reducir la dimensionalidad de cada imagen mientras se conserva la mayor parte de la información visual.\n",
    "\n",
    "Cómo funciona con imágenes:<br>\n",
    "\n",
    "1. **Vectorización:** Cada imagen se transforma en un vector. Por ejemplo, una imagen de 64×64 píxeles en color RGB se convierte en un vector de 64×64×3 = 12,288 dimensiones.<br>\n",
    "2. **Cálculo de componentes principales:** PCA identifica las direcciones (componentes) en el espacio de características donde los datos tienen mayor varianza.<br>\n",
    "3. **Reducción de dimensión:** Se proyectan los vectores de las imágenes en un espacio de menor dimensión (por ejemplo 50 o 100 componentes), preservando las características más relevantes y descartando ruido o redundancia.<br>\n",
    "4. **Usos posteriores:** Los vectores reducidos pueden usarse para clustering (K-means, DBSCAN), visualización en 2D/3D o incluso como preprocesamiento antes de entrenar modelos de aprendizaje automático.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd182eb6-a03e-437f-8787-715f813a5579",
   "metadata": {},
   "source": [
    "**Modelos no vistos en clase**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc4f3af-45f6-4718-982c-45c4d5ce075b",
   "metadata": {},
   "source": [
    "**t-SNE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dca2de-fad0-4b8c-9885-a7b6faa23c76",
   "metadata": {},
   "source": [
    "El t-SNE (t-distributed Stochastic Neighbor Embedding) es una técnica de reducción de dimensionalidad no lineal muy usada para visualizar datasets de imágenes en 2D o 3D. Su objetivo es conservar las relaciones de similitud entre las imágenes: las que son parecidas quedan cerca, y las distintas, lejos.<br><br>\n",
    "Cómo funciona t-SNE con imágenes:<br>\n",
    "1. **Representación numérica:** cada imagen se convierte en un vector (por ejemplo, con embeddings de una red neuronal o usando los valores de píxeles).\n",
    "2. **Cálculo de similitudes:** t-SNE mide qué tan similares son los vectores en el espacio original.\n",
    "3. **Proyección a 2D o 3D:** crea un nuevo espacio de menor dimensión donde esas relaciones se mantienen lo más posible.\n",
    "4. **Visualización:** al graficar los puntos resultantes, las imágenes similares aparecen agrupadas visualmente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64449210-de9b-4643-833f-2acce397d7f4",
   "metadata": {},
   "source": [
    "**Mean Shift**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e2d1e8-aa6b-47db-8a6d-8db83276e709",
   "metadata": {},
   "source": [
    "El algoritmo Mean Shift es una técnica de aprendizaje no supervisado utilizada para agrupar datos (clustering), incluyendo datasets de imágenes, sin necesidad de especificar cuántos grupos habrá, a diferencia de K-means. En imágenes, se usa para segmentar regiones visualmente similares o agrupar imágenes por características comunes.<br>\n",
    "\n",
    "Cómo funciona Mean Shift con imágenes:\n",
    "1. **Representación de imágenes:** cada imagen se convierte en un vector de características (por ejemplo, con histogramas de color, valores de píxeles o embeddings de una red neuronal).\n",
    "2. **Núcleo de densidad:** Mean Shift coloca una “ventana” (kernel) en el espacio de datos y calcula la media local (el punto hacia donde hay más densidad).\n",
    "3. **Desplazamiento iterativo:** el centro de la ventana se mueve hacia la densidad más alta.\n",
    "4. **Agrupamiento:** los puntos que convergen al mismo máximo de densidad se consideran parte del mismo grupo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52ce612-cf0f-45c3-948d-0bc07eb5b518",
   "metadata": {},
   "source": [
    "**¿Qué métrica de evaluación utilizarás y por qué?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9ff866-4528-4385-9720-ede7ea95bc30",
   "metadata": {},
   "source": [
    "En un aprendizaje no supervisado con dataset de imágenes, la elección de la métrica de evaluación depende del tipo de modelo y del objetivo (por ejemplo, clustering o reducción de dimensionalidad).<br>\n",
    "\n",
    "Si aplicas K-means, DBSCAN o Mean Shift, las métrica más comun es Silhouette Score, funciona asi:\n",
    "- **Qué mide:** qué tan bien separados están los clusters y qué tan compactos son internamente.\n",
    "- **Fórmula:** compara la distancia media entre puntos del mismo cluster y de diferentes clusters.\n",
    "- **Rango:** de -1 a 1 (más cercano a 1 = mejor separación).\n",
    "- **Por qué usarla:** no requiere etiquetas y ofrece una buena idea de la calidad de los grupos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3e3ed6-970b-4080-8632-3a1366a20b87",
   "metadata": {},
   "source": [
    "**¿Quiénes serían los usuarios o beneficiarios del modelo?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c50179a-ab53-48a9-9e18-ff5aa4495eff",
   "metadata": {},
   "source": [
    "Los usuarios o beneficiarios de un modelo de aprendizaje no supervisado con dataset de imágenes dependerán del propósito del proyecto, pero en general incluyen:\n",
    "\n",
    "1. Investigadores y científicos de datos.\n",
    "- Utilizan el modelo para explorar grandes colecciones de imágenes sin etiquetar, detectar patrones visuales y generar hipótesis.\n",
    "- Beneficio: reducen el tiempo y costo del etiquetado manual.\n",
    "\n",
    "2. Empresas de tecnología e inteligencia artificial.\n",
    "- Aplican el modelo para organizar, clasificar o segmentar bases de datos visuales (por ejemplo, fotos de productos, rostros o escenas).\n",
    "- Beneficio: optimizan motores de búsqueda de imágenes y sistemas de recomendación visual.\n",
    "\n",
    "3. Plataformas de comercio electrónico.\n",
    "- Usan los clusters para agrupar productos similares visualmente, como ropa o accesorios.\n",
    "- Beneficio: mejoran la experiencia del usuario al sugerir artículos parecidos (“productos similares”).\n",
    "\n",
    "4. Instituciones académicas o de salud.\n",
    "- En análisis médico, el modelo puede agrupar imágenes de radiografías o tejidos con características comunes.\n",
    "- Beneficio: ayuda a descubrir patrones que orienten diagnósticos o investigaciones.\n",
    "\n",
    "5. Creadores de contenido o de archivos digitales.\n",
    "- Permite organizar colecciones grandes de imágenes históricas o artísticas según similitud visual.\n",
    "- Beneficio: mejora la búsqueda, clasificación y preservación digital."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e38dd-01e7-476d-ab9e-c924c5262230",
   "metadata": {},
   "source": [
    "**¿Qué esperas lograr con tu modelo? (clasificar, predecir, segmentar, etc.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58701382-74d3-4cef-a30d-2ce3b106d3b8",
   "metadata": {},
   "source": [
    "Con un modelo de aprendizaje no supervisado aplicado a un dataset de imágenes, el objetivo principal es segmentar o agrupar las imágenes según su similitud visual, no clasificar ni predecir etiquetas predefinidas.<br>\n",
    "\n",
    "Específicamente se espera lograr:\n",
    "- Descubrir patrones ocultos: identificar grupos de imágenes que comparten características similares, como color, forma o textura.\n",
    "- Organización automática: reducir la necesidad de etiquetado manual y facilitar la gestión de grandes colecciones de imágenes.\n",
    "- Preparación para análisis posterior: generar clústeres que luego puedan usarse para recomendaciones, búsqueda por similitud o visualización.\n",
    "- Detección de outliers: identificar imágenes atípicas o ruidosas que no encajan en ningún grupo.\n",
    "- En resumen, el modelo busca segmentar y estructurar visualmente el dataset, permitiendo interpretar y explorar grandes volúmenes de imágenes de manera eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fe4a7a-8a21-44c2-ac68-5f3316bc84c0",
   "metadata": {},
   "source": [
    "**¿Qué herramientas planeas usar? (PyTorch, TensorFlow, Keras, etc.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c4ec60-5321-4078-b848-64e5274fc318",
   "metadata": {},
   "source": [
    "- Para extracción de embeddings y preprocesamiento: TensorFlow/Keras o PyTorch + OpenCV/PIL.\n",
    "- Para clustering y evaluación: scikit-learn.\n",
    "- Para visualización y manejo de datos: matplotlib, seaborn y pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8531a9-3714-479e-95de-49d21814b32e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
